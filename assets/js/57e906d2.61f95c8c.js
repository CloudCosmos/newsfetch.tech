"use strict";(self.webpackChunknewsfetch_website=self.webpackChunknewsfetch_website||[]).push([[840],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>p});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=a.createContext({}),l=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=l(e.components);return a.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),h=l(n),p=r,f=h["".concat(c,".").concat(p)]||h[p]||u[p]||o;return n?a.createElement(f,i(i({ref:t},d),{},{components:n})):a.createElement(f,i({ref:t},d))}));function p(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=h;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var l=2;l<o;l++)i[l]=n[l];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},7044:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var a=n(7462),r=(n(7294),n(3905));const o={sidebar_position:81},i="NewsFetch - A Brief History",s={unversionedId:"newsfetch-history",id:"newsfetch-history",title:"NewsFetch - A Brief History",description:"CloudCosmos has been exploring News content for a while now! We have worked with clients in building large",source:"@site/docs/newsfetch-history.md",sourceDirName:".",slug:"/newsfetch-history",permalink:"/docs/newsfetch-history",draft:!1,tags:[],version:"current",sidebarPosition:81,frontMatter:{sidebar_position:81},sidebar:"tutorialSidebar",previous:{title:"Sample Data",permalink:"/docs/features/sample-data"},next:{title:"Contributing to NewsFetch",permalink:"/docs/contributing"}},c={},l=[{value:"RedactWiz",id:"redactwiz",level:2},{value:"Textalytics",id:"textalytics",level:2},{value:"ShukraAI",id:"shukraai",level:2}],d={toc:l};function u(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"newsfetch---a-brief-history"},"NewsFetch - A Brief History"),(0,r.kt)("p",null,"CloudCosmos has been exploring News content for a while now! We have worked with clients in building large\nscale search engines for News, setting up data ingestion pipelines to rapidly consume massive volumes of News\nfor near-real-time needs of users, enriching News using various techniques and strategies (NLP, Machine Learning,\nrule engines etc.)."),(0,r.kt)("p",null,"NewsFetch provides a platform to explore News content in a structured and easy to use manner. It builds on the\ndata that CommonCrawl has made available to the public, and in particular the CC-NEWS dataset. CC-NEWS crawls generate\nabout 10-15 archive files per day. Each archive has 20-25k documents (news articles) within it and these cover\nmultiple languages."),(0,r.kt)("h2",{id:"redactwiz"},"RedactWiz"),(0,r.kt)("p",null,"One of the first products that CloudCosmos built was RedactWiz (not in production anymore).\nRedactWiz enabled AI power redaction to safeguard sensitive information from documents. It was a hosted\napp that enabled documents in MS Word, PDF and a few image formats to be uploaded, with configuration choices\nthat further provided a capability for extracted textual content to be erased/redacted (blacked out in PDF\nand images; replaced with constant length character strings in text etc.) based on identified entities (NER) and\ncontext around the entities (word span, sentences, paragraphs etc.)."),(0,r.kt)("p",null,"RedactWiz was designed to run in air-gap environments. The product hosted all the AI/ML models and the code\nrequired for the features without needing to make any API calls to external vendor products or platforms."),(0,r.kt)("h2",{id:"textalytics"},(0,r.kt)("a",{parentName:"h2",href:"https://www.textalytics.tech/"},"Textalytics")),(0,r.kt)("p",null,"An ask for the RedactWiz platform was capability to invoke the features via an API. Textalytics was built to\naddress this ask and offers features beyond just the redaction use-case."),(0,r.kt)("p",null,"Textalytics offered features like Named Entity Recognition (NER), Entity Linking and Resolution (with WikiData),\nSummarization etc. via a standardized APIs. These APIs also have the glue to make them work with cloud offerings\nwith similar features. The focus with Textalytics was to showcase the capabilities that CloudCosmos team has with\nbuilding and hosting custom models: all the way from obtaining content, cleaning, tagging for specific use-cases,\ntraining models for desired F1 scores and hosting it for inference."),(0,r.kt)("p",null,"The core capabilities of Textalytics was extended to apply to open-source and cloud based NLP engines and all of\nthis was open-sourced as ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/textalytics"},"Textalytics Open-Source")),(0,r.kt)("h2",{id:"shukraai"},(0,r.kt)("a",{parentName:"h2",href:"https://www.shukra.ai/"},"ShukraAI")),(0,r.kt)("p",null,"Shukra build upon Textalytics."),(0,r.kt)("p",null,"Shukra, was a large repository of enrichments for content in open datasets. The dataset being enriched was\nCC-NEWS (Common Crawl News)."),(0,r.kt)("p",null,"Shukra\u2019s goal was to provide an opinionated set of enrichments (NER, Summarization, Zero-Shot Classification,\nSentiment Detection etc.) from widely popular pre-trained models available from platforms like HuggingFace, Spacy,\nAllen AI, Flair etc. for every document in CC-NEWS. These enrichments were generated for all the historic content,\nstarting from about August 2016, when CC-NEWS started the News database, and keeping it as real-time as it was\nfeasible and in-sync with the latest crawl dump from CC-NEWS."),(0,r.kt)("p",null,"Shukra aimed to extract enrichments from all of CC-NEWS content, and started with the languages for\nwhich pre-trained models were available. The estimated number of documents per day were over 50k documents, and\nthere were be at least half a dozen to a dozen enrichments per document that were being generated."),(0,r.kt)("h1",{id:"newsfetch-and-the-future"},"NewsFetch and the future"),(0,r.kt)("p",null,"We are now open-sourcing the code that was the backbone of Shukra and to make it available for the community\nto use and build upon. This combined with Textalytics Open-Source should enable one to build various applications\nthat harness News for insights and data."),(0,r.kt)("h1",{id:"cloudcosmos"},"CloudCosmos"),(0,r.kt)("p",null,"You can find the more information about CloudCosmos at ",(0,r.kt)("a",{parentName:"p",href:"https://cloudcosmos.tech/"},"https://cloudcosmos.tech/")))}u.isMDXComponent=!0}}]);